{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8d6218c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/root2\n"
     ]
    }
   ],
   "source": [
    "%cd /home/root2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ffece73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdvSemiSeg\t\t\t\tNotebooks   save\r\n",
      "CCT\t\t\t\t\tdata\t    tmux-client-32898.log\r\n",
      "Miniconda3-py37_4.12.0-Linux-x86_64.sh\tminiconda3  tmux-server-32900.log\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81f4ef42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f6f9eb9f730>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d53c190",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image Shape: torch.Size([1, 32, 32])\n",
      "\n",
      "Training Set:   55000 samples\n",
      "Validation Set:   5000 samples\n",
      "Test Set:       10000 samples\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "transform=transforms.Compose([\n",
    "        # Pad images with 0s\n",
    "        transforms.Pad((0,4,4,0), fill=0, padding_mode='constant'),\n",
    "    \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,)),\n",
    "        ])\n",
    "dataset_full = datasets.MNIST('./data', train=True, download=True,\n",
    "                   transform=transform)\n",
    "valid_size = 5000\n",
    "train_size = len(dataset_full) - 5000\n",
    "dataset_train, dataset_valid = torch.utils.data.random_split(dataset_full, [train_size, valid_size], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "dataset_test = datasets.MNIST('./data', train=False,\n",
    "                   transform=transform)\n",
    "\n",
    "train_kwargs = {'batch_size': 128, 'shuffle': True}\n",
    "valid_kwargs = {'batch_size': 128, 'shuffle': False}\n",
    "test_kwargs = {'batch_size': 128, 'shuffle': False}\n",
    "train_loader = torch.utils.data.DataLoader(dataset_train,**train_kwargs)\n",
    "valid_loader = torch.utils.data.DataLoader(dataset_valid,**valid_kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(dataset_test, **test_kwargs)\n",
    "\n",
    "print()\n",
    "print(\"Image Shape: {}\".format(dataset_train[0][0].shape))\n",
    "print()\n",
    "print(\"Training Set:   {} samples\".format(len(dataset_train)))\n",
    "print(\"Validation Set:   {} samples\".format(len(dataset_valid)))\n",
    "print(\"Test Set:       {} samples\".format(len(dataset_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b3ecbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load classifier\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, (5,5)),\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2)\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, (5,5)),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(2,2)\n",
    "        )\n",
    "        self.fc1   = nn.Linear(400, 120)\n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.flatten(start_dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e4b2e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train & test part from https://github.com/activatedgeek/LeNet-5\n",
    "def train(epoch):\n",
    "    global cur_batch_win\n",
    "    net.train()\n",
    "    loss_list, batch_list = [], []\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = net(images.cuda())\n",
    "        loss = criterion(output, labels.cuda())\n",
    "\n",
    "        loss_list.append(loss.detach().cpu().item())\n",
    "        batch_list.append(i+1)\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print('Train - Epoch %d, Batch: %d, Loss: %f' % (epoch, i, loss.detach().cpu().item()))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bd71cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = LeNet().cuda()\n",
    "print (net)\n",
    "\n",
    "learning_rate = 0.001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "753dbcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(target_loader, target_dataset):\n",
    "    predictions = []\n",
    "    net.eval()\n",
    "    total_correct = 0\n",
    "    avg_loss = 0.0\n",
    "    for i, (images, labels) in enumerate(target_loader):\n",
    "        output = net(images.cuda())\n",
    "        avg_loss += criterion(output, labels.cuda()).sum()\n",
    "        pred = output.detach().max(1)[1]\n",
    "        total_correct += pred.eq(labels.cuda().view_as(pred)).sum()\n",
    "        predictions.append(pred)\n",
    "\n",
    "    avg_loss /= len(target_dataset)\n",
    "    print('Test Avg. Loss: %f, Accuracy: %f' % (avg_loss.detach().cpu().item(), float(total_correct) / len(target_dataset)))\n",
    "    accuracy    = float(total_correct) / len(target_dataset)\n",
    "    return accuracy, np.array(torch.cat(predictions).cpu())\n",
    "    #or if you are in latest Pytorch world\n",
    "    #return accuracy, np.array(torch.vstack(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da487aee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "\n",
      "Train - Epoch 1, Batch: 0, Loss: 2.305326\n",
      "Train - Epoch 1, Batch: 10, Loss: 1.801166\n",
      "Train - Epoch 1, Batch: 20, Loss: 1.173530\n",
      "Train - Epoch 1, Batch: 30, Loss: 0.818145\n",
      "Train - Epoch 1, Batch: 40, Loss: 0.450485\n",
      "Train - Epoch 1, Batch: 50, Loss: 0.447638\n",
      "Train - Epoch 1, Batch: 60, Loss: 0.375104\n",
      "Train - Epoch 1, Batch: 70, Loss: 0.290163\n",
      "Train - Epoch 1, Batch: 80, Loss: 0.172211\n",
      "Train - Epoch 1, Batch: 90, Loss: 0.342018\n",
      "Train - Epoch 1, Batch: 100, Loss: 0.191067\n",
      "Train - Epoch 1, Batch: 110, Loss: 0.170591\n",
      "Train - Epoch 1, Batch: 120, Loss: 0.200742\n",
      "Train - Epoch 1, Batch: 130, Loss: 0.139756\n",
      "Train - Epoch 1, Batch: 140, Loss: 0.112938\n",
      "Train - Epoch 1, Batch: 150, Loss: 0.093955\n",
      "Train - Epoch 1, Batch: 160, Loss: 0.254051\n",
      "Train - Epoch 1, Batch: 170, Loss: 0.140887\n",
      "Train - Epoch 1, Batch: 180, Loss: 0.223995\n",
      "Train - Epoch 1, Batch: 190, Loss: 0.127031\n",
      "Train - Epoch 1, Batch: 200, Loss: 0.225062\n",
      "Train - Epoch 1, Batch: 210, Loss: 0.140406\n",
      "Train - Epoch 1, Batch: 220, Loss: 0.174806\n",
      "Train - Epoch 1, Batch: 230, Loss: 0.167422\n",
      "Train - Epoch 1, Batch: 240, Loss: 0.056379\n",
      "Train - Epoch 1, Batch: 250, Loss: 0.118694\n",
      "Train - Epoch 1, Batch: 260, Loss: 0.087042\n",
      "Train - Epoch 1, Batch: 270, Loss: 0.048330\n",
      "Train - Epoch 1, Batch: 280, Loss: 0.099032\n",
      "Train - Epoch 1, Batch: 290, Loss: 0.108715\n",
      "Train - Epoch 1, Batch: 300, Loss: 0.135974\n",
      "Train - Epoch 1, Batch: 310, Loss: 0.123955\n",
      "Train - Epoch 1, Batch: 320, Loss: 0.035724\n",
      "Train - Epoch 1, Batch: 330, Loss: 0.065155\n",
      "Train - Epoch 1, Batch: 340, Loss: 0.112799\n",
      "Train - Epoch 1, Batch: 350, Loss: 0.057463\n",
      "Train - Epoch 1, Batch: 360, Loss: 0.106332\n",
      "Train - Epoch 1, Batch: 370, Loss: 0.113314\n",
      "Train - Epoch 1, Batch: 380, Loss: 0.117701\n",
      "Train - Epoch 1, Batch: 390, Loss: 0.033081\n",
      "Train - Epoch 1, Batch: 400, Loss: 0.035781\n",
      "Train - Epoch 1, Batch: 410, Loss: 0.124214\n",
      "Train - Epoch 1, Batch: 420, Loss: 0.085995\n",
      "Test Avg. Loss: 0.000677, Accuracy: 0.973800\n",
      "EPOCH 1 ...\n",
      "Validation Accuracy = 0.974\n",
      "\n",
      "Model saved\n",
      "Train - Epoch 2, Batch: 0, Loss: 0.049814\n",
      "Train - Epoch 2, Batch: 10, Loss: 0.092039\n",
      "Train - Epoch 2, Batch: 20, Loss: 0.013613\n",
      "Train - Epoch 2, Batch: 30, Loss: 0.082359\n",
      "Train - Epoch 2, Batch: 40, Loss: 0.055028\n",
      "Train - Epoch 2, Batch: 50, Loss: 0.060382\n",
      "Train - Epoch 2, Batch: 60, Loss: 0.103309\n",
      "Train - Epoch 2, Batch: 70, Loss: 0.076652\n",
      "Train - Epoch 2, Batch: 80, Loss: 0.049685\n",
      "Train - Epoch 2, Batch: 90, Loss: 0.050828\n",
      "Train - Epoch 2, Batch: 100, Loss: 0.025538\n",
      "Train - Epoch 2, Batch: 110, Loss: 0.104719\n",
      "Train - Epoch 2, Batch: 120, Loss: 0.030740\n",
      "Train - Epoch 2, Batch: 130, Loss: 0.058689\n",
      "Train - Epoch 2, Batch: 140, Loss: 0.020055\n",
      "Train - Epoch 2, Batch: 150, Loss: 0.124674\n",
      "Train - Epoch 2, Batch: 160, Loss: 0.038755\n",
      "Train - Epoch 2, Batch: 170, Loss: 0.063571\n",
      "Train - Epoch 2, Batch: 180, Loss: 0.019101\n",
      "Train - Epoch 2, Batch: 190, Loss: 0.118797\n",
      "Train - Epoch 2, Batch: 200, Loss: 0.029016\n",
      "Train - Epoch 2, Batch: 210, Loss: 0.050105\n",
      "Train - Epoch 2, Batch: 220, Loss: 0.107964\n",
      "Train - Epoch 2, Batch: 230, Loss: 0.023910\n",
      "Train - Epoch 2, Batch: 240, Loss: 0.148106\n",
      "Train - Epoch 2, Batch: 250, Loss: 0.031979\n",
      "Train - Epoch 2, Batch: 260, Loss: 0.041060\n",
      "Train - Epoch 2, Batch: 270, Loss: 0.083573\n",
      "Train - Epoch 2, Batch: 280, Loss: 0.044265\n",
      "Train - Epoch 2, Batch: 290, Loss: 0.040792\n",
      "Train - Epoch 2, Batch: 300, Loss: 0.118515\n",
      "Train - Epoch 2, Batch: 310, Loss: 0.101894\n",
      "Train - Epoch 2, Batch: 320, Loss: 0.024884\n",
      "Train - Epoch 2, Batch: 330, Loss: 0.031111\n",
      "Train - Epoch 2, Batch: 340, Loss: 0.040401\n",
      "Train - Epoch 2, Batch: 350, Loss: 0.070817\n",
      "Train - Epoch 2, Batch: 360, Loss: 0.071681\n",
      "Train - Epoch 2, Batch: 370, Loss: 0.047325\n",
      "Train - Epoch 2, Batch: 380, Loss: 0.025886\n",
      "Train - Epoch 2, Batch: 390, Loss: 0.060393\n",
      "Train - Epoch 2, Batch: 400, Loss: 0.073154\n",
      "Train - Epoch 2, Batch: 410, Loss: 0.035567\n",
      "Train - Epoch 2, Batch: 420, Loss: 0.106433\n",
      "Test Avg. Loss: 0.000642, Accuracy: 0.974200\n",
      "EPOCH 2 ...\n",
      "Validation Accuracy = 0.974\n",
      "\n",
      "Model saved\n",
      "Train - Epoch 3, Batch: 0, Loss: 0.078795\n",
      "Train - Epoch 3, Batch: 10, Loss: 0.067020\n",
      "Train - Epoch 3, Batch: 20, Loss: 0.038643\n",
      "Train - Epoch 3, Batch: 30, Loss: 0.066769\n",
      "Train - Epoch 3, Batch: 40, Loss: 0.026458\n",
      "Train - Epoch 3, Batch: 50, Loss: 0.058891\n",
      "Train - Epoch 3, Batch: 60, Loss: 0.039333\n",
      "Train - Epoch 3, Batch: 70, Loss: 0.032574\n",
      "Train - Epoch 3, Batch: 80, Loss: 0.060635\n",
      "Train - Epoch 3, Batch: 90, Loss: 0.077497\n",
      "Train - Epoch 3, Batch: 100, Loss: 0.046643\n",
      "Train - Epoch 3, Batch: 110, Loss: 0.009492\n",
      "Train - Epoch 3, Batch: 120, Loss: 0.010524\n",
      "Train - Epoch 3, Batch: 130, Loss: 0.021088\n",
      "Train - Epoch 3, Batch: 140, Loss: 0.040994\n",
      "Train - Epoch 3, Batch: 150, Loss: 0.102579\n",
      "Train - Epoch 3, Batch: 160, Loss: 0.096309\n",
      "Train - Epoch 3, Batch: 170, Loss: 0.085291\n",
      "Train - Epoch 3, Batch: 180, Loss: 0.027664\n",
      "Train - Epoch 3, Batch: 190, Loss: 0.038680\n",
      "Train - Epoch 3, Batch: 200, Loss: 0.016776\n",
      "Train - Epoch 3, Batch: 210, Loss: 0.040579\n",
      "Train - Epoch 3, Batch: 220, Loss: 0.023805\n",
      "Train - Epoch 3, Batch: 230, Loss: 0.035718\n",
      "Train - Epoch 3, Batch: 240, Loss: 0.027174\n",
      "Train - Epoch 3, Batch: 250, Loss: 0.029888\n",
      "Train - Epoch 3, Batch: 260, Loss: 0.024725\n",
      "Train - Epoch 3, Batch: 270, Loss: 0.022596\n",
      "Train - Epoch 3, Batch: 280, Loss: 0.025519\n",
      "Train - Epoch 3, Batch: 290, Loss: 0.048175\n",
      "Train - Epoch 3, Batch: 300, Loss: 0.032936\n",
      "Train - Epoch 3, Batch: 310, Loss: 0.046301\n",
      "Train - Epoch 3, Batch: 320, Loss: 0.009703\n",
      "Train - Epoch 3, Batch: 330, Loss: 0.094257\n",
      "Train - Epoch 3, Batch: 340, Loss: 0.009468\n",
      "Train - Epoch 3, Batch: 350, Loss: 0.071007\n",
      "Train - Epoch 3, Batch: 360, Loss: 0.080200\n",
      "Train - Epoch 3, Batch: 370, Loss: 0.046263\n",
      "Train - Epoch 3, Batch: 380, Loss: 0.012283\n",
      "Train - Epoch 3, Batch: 390, Loss: 0.053975\n",
      "Train - Epoch 3, Batch: 400, Loss: 0.062719\n",
      "Train - Epoch 3, Batch: 410, Loss: 0.049631\n",
      "Train - Epoch 3, Batch: 420, Loss: 0.052479\n",
      "Test Avg. Loss: 0.000417, Accuracy: 0.984200\n",
      "EPOCH 3 ...\n",
      "Validation Accuracy = 0.984\n",
      "\n",
      "Model saved\n",
      "Train - Epoch 4, Batch: 0, Loss: 0.024089\n",
      "Train - Epoch 4, Batch: 10, Loss: 0.040808\n",
      "Train - Epoch 4, Batch: 20, Loss: 0.026175\n",
      "Train - Epoch 4, Batch: 30, Loss: 0.043053\n",
      "Train - Epoch 4, Batch: 40, Loss: 0.063308\n",
      "Train - Epoch 4, Batch: 50, Loss: 0.049671\n",
      "Train - Epoch 4, Batch: 60, Loss: 0.046201\n",
      "Train - Epoch 4, Batch: 70, Loss: 0.071039\n",
      "Train - Epoch 4, Batch: 80, Loss: 0.044533\n",
      "Train - Epoch 4, Batch: 90, Loss: 0.090454\n",
      "Train - Epoch 4, Batch: 100, Loss: 0.012818\n",
      "Train - Epoch 4, Batch: 110, Loss: 0.016658\n",
      "Train - Epoch 4, Batch: 120, Loss: 0.047913\n",
      "Train - Epoch 4, Batch: 130, Loss: 0.009057\n",
      "Train - Epoch 4, Batch: 140, Loss: 0.017281\n",
      "Train - Epoch 4, Batch: 150, Loss: 0.025594\n",
      "Train - Epoch 4, Batch: 160, Loss: 0.006114\n",
      "Train - Epoch 4, Batch: 170, Loss: 0.095280\n",
      "Train - Epoch 4, Batch: 180, Loss: 0.030820\n",
      "Train - Epoch 4, Batch: 190, Loss: 0.051768\n",
      "Train - Epoch 4, Batch: 200, Loss: 0.039838\n",
      "Train - Epoch 4, Batch: 210, Loss: 0.061254\n",
      "Train - Epoch 4, Batch: 220, Loss: 0.025406\n",
      "Train - Epoch 4, Batch: 230, Loss: 0.014135\n",
      "Train - Epoch 4, Batch: 240, Loss: 0.010637\n",
      "Train - Epoch 4, Batch: 250, Loss: 0.031560\n",
      "Train - Epoch 4, Batch: 260, Loss: 0.040243\n",
      "Train - Epoch 4, Batch: 270, Loss: 0.027870\n",
      "Train - Epoch 4, Batch: 280, Loss: 0.050977\n",
      "Train - Epoch 4, Batch: 290, Loss: 0.029850\n",
      "Train - Epoch 4, Batch: 300, Loss: 0.054602\n",
      "Train - Epoch 4, Batch: 310, Loss: 0.041144\n",
      "Train - Epoch 4, Batch: 320, Loss: 0.011992\n",
      "Train - Epoch 4, Batch: 330, Loss: 0.014573\n",
      "Train - Epoch 4, Batch: 340, Loss: 0.111952\n",
      "Train - Epoch 4, Batch: 350, Loss: 0.046456\n",
      "Train - Epoch 4, Batch: 360, Loss: 0.042149\n",
      "Train - Epoch 4, Batch: 370, Loss: 0.055712\n",
      "Train - Epoch 4, Batch: 380, Loss: 0.048874\n",
      "Train - Epoch 4, Batch: 390, Loss: 0.035388\n",
      "Train - Epoch 4, Batch: 400, Loss: 0.027080\n",
      "Train - Epoch 4, Batch: 410, Loss: 0.041421\n",
      "Train - Epoch 4, Batch: 420, Loss: 0.012970\n",
      "Test Avg. Loss: 0.000420, Accuracy: 0.982200\n",
      "EPOCH 4 ...\n",
      "Validation Accuracy = 0.982\n",
      "\n",
      "Model saved\n",
      "Train - Epoch 5, Batch: 0, Loss: 0.026668\n",
      "Train - Epoch 5, Batch: 10, Loss: 0.037903\n",
      "Train - Epoch 5, Batch: 20, Loss: 0.032554\n",
      "Train - Epoch 5, Batch: 30, Loss: 0.043194\n",
      "Train - Epoch 5, Batch: 40, Loss: 0.043135\n",
      "Train - Epoch 5, Batch: 50, Loss: 0.007450\n",
      "Train - Epoch 5, Batch: 60, Loss: 0.032590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Epoch 5, Batch: 70, Loss: 0.012586\n",
      "Train - Epoch 5, Batch: 80, Loss: 0.006953\n",
      "Train - Epoch 5, Batch: 90, Loss: 0.002565\n",
      "Train - Epoch 5, Batch: 100, Loss: 0.029601\n",
      "Train - Epoch 5, Batch: 110, Loss: 0.007108\n",
      "Train - Epoch 5, Batch: 120, Loss: 0.040104\n",
      "Train - Epoch 5, Batch: 130, Loss: 0.029370\n",
      "Train - Epoch 5, Batch: 140, Loss: 0.006945\n",
      "Train - Epoch 5, Batch: 150, Loss: 0.016986\n",
      "Train - Epoch 5, Batch: 160, Loss: 0.032072\n",
      "Train - Epoch 5, Batch: 170, Loss: 0.044288\n",
      "Train - Epoch 5, Batch: 180, Loss: 0.101612\n",
      "Train - Epoch 5, Batch: 190, Loss: 0.030361\n",
      "Train - Epoch 5, Batch: 200, Loss: 0.013452\n",
      "Train - Epoch 5, Batch: 210, Loss: 0.003021\n",
      "Train - Epoch 5, Batch: 220, Loss: 0.006277\n",
      "Train - Epoch 5, Batch: 230, Loss: 0.041248\n",
      "Train - Epoch 5, Batch: 240, Loss: 0.024702\n",
      "Train - Epoch 5, Batch: 250, Loss: 0.002762\n",
      "Train - Epoch 5, Batch: 260, Loss: 0.063514\n",
      "Train - Epoch 5, Batch: 270, Loss: 0.016360\n",
      "Train - Epoch 5, Batch: 280, Loss: 0.030750\n",
      "Train - Epoch 5, Batch: 290, Loss: 0.021671\n",
      "Train - Epoch 5, Batch: 300, Loss: 0.006310\n",
      "Train - Epoch 5, Batch: 310, Loss: 0.022365\n",
      "Train - Epoch 5, Batch: 320, Loss: 0.032225\n",
      "Train - Epoch 5, Batch: 330, Loss: 0.019473\n",
      "Train - Epoch 5, Batch: 340, Loss: 0.013362\n",
      "Train - Epoch 5, Batch: 350, Loss: 0.018352\n",
      "Train - Epoch 5, Batch: 360, Loss: 0.012163\n",
      "Train - Epoch 5, Batch: 370, Loss: 0.012165\n",
      "Train - Epoch 5, Batch: 380, Loss: 0.005755\n",
      "Train - Epoch 5, Batch: 390, Loss: 0.005575\n",
      "Train - Epoch 5, Batch: 400, Loss: 0.051626\n",
      "Train - Epoch 5, Batch: 410, Loss: 0.075912\n",
      "Train - Epoch 5, Batch: 420, Loss: 0.012704\n",
      "Test Avg. Loss: 0.000338, Accuracy: 0.986000\n",
      "EPOCH 5 ...\n",
      "Validation Accuracy = 0.986\n",
      "\n",
      "Model saved\n",
      "Train - Epoch 6, Batch: 0, Loss: 0.008123\n",
      "Train - Epoch 6, Batch: 10, Loss: 0.032884\n",
      "Train - Epoch 6, Batch: 20, Loss: 0.011944\n",
      "Train - Epoch 6, Batch: 30, Loss: 0.011647\n",
      "Train - Epoch 6, Batch: 40, Loss: 0.026423\n",
      "Train - Epoch 6, Batch: 50, Loss: 0.032412\n",
      "Train - Epoch 6, Batch: 60, Loss: 0.045146\n",
      "Train - Epoch 6, Batch: 70, Loss: 0.011623\n",
      "Train - Epoch 6, Batch: 80, Loss: 0.021087\n",
      "Train - Epoch 6, Batch: 90, Loss: 0.006569\n",
      "Train - Epoch 6, Batch: 100, Loss: 0.063076\n",
      "Train - Epoch 6, Batch: 110, Loss: 0.040591\n",
      "Train - Epoch 6, Batch: 120, Loss: 0.001115\n",
      "Train - Epoch 6, Batch: 130, Loss: 0.022319\n",
      "Train - Epoch 6, Batch: 140, Loss: 0.019285\n",
      "Train - Epoch 6, Batch: 150, Loss: 0.014075\n",
      "Train - Epoch 6, Batch: 160, Loss: 0.003631\n",
      "Train - Epoch 6, Batch: 170, Loss: 0.012595\n",
      "Train - Epoch 6, Batch: 180, Loss: 0.005628\n",
      "Train - Epoch 6, Batch: 190, Loss: 0.036397\n",
      "Train - Epoch 6, Batch: 200, Loss: 0.006556\n",
      "Train - Epoch 6, Batch: 210, Loss: 0.002483\n",
      "Train - Epoch 6, Batch: 220, Loss: 0.057682\n",
      "Train - Epoch 6, Batch: 230, Loss: 0.051239\n",
      "Train - Epoch 6, Batch: 240, Loss: 0.021111\n",
      "Train - Epoch 6, Batch: 250, Loss: 0.003484\n",
      "Train - Epoch 6, Batch: 260, Loss: 0.035095\n",
      "Train - Epoch 6, Batch: 270, Loss: 0.006326\n",
      "Train - Epoch 6, Batch: 280, Loss: 0.018602\n",
      "Train - Epoch 6, Batch: 290, Loss: 0.026784\n",
      "Train - Epoch 6, Batch: 300, Loss: 0.042574\n",
      "Train - Epoch 6, Batch: 310, Loss: 0.020005\n",
      "Train - Epoch 6, Batch: 320, Loss: 0.037745\n",
      "Train - Epoch 6, Batch: 330, Loss: 0.086556\n",
      "Train - Epoch 6, Batch: 340, Loss: 0.024268\n",
      "Train - Epoch 6, Batch: 350, Loss: 0.005190\n",
      "Train - Epoch 6, Batch: 360, Loss: 0.022312\n",
      "Train - Epoch 6, Batch: 370, Loss: 0.025018\n",
      "Train - Epoch 6, Batch: 380, Loss: 0.010494\n",
      "Train - Epoch 6, Batch: 390, Loss: 0.069034\n",
      "Train - Epoch 6, Batch: 400, Loss: 0.041884\n",
      "Train - Epoch 6, Batch: 410, Loss: 0.006278\n",
      "Train - Epoch 6, Batch: 420, Loss: 0.005486\n",
      "Test Avg. Loss: 0.000401, Accuracy: 0.984000\n",
      "EPOCH 6 ...\n",
      "Validation Accuracy = 0.984\n",
      "\n",
      "Model saved\n",
      "Train - Epoch 7, Batch: 0, Loss: 0.018595\n",
      "Train - Epoch 7, Batch: 10, Loss: 0.034457\n",
      "Train - Epoch 7, Batch: 20, Loss: 0.005708\n",
      "Train - Epoch 7, Batch: 30, Loss: 0.027694\n",
      "Train - Epoch 7, Batch: 40, Loss: 0.052467\n",
      "Train - Epoch 7, Batch: 50, Loss: 0.049893\n",
      "Train - Epoch 7, Batch: 60, Loss: 0.061296\n",
      "Train - Epoch 7, Batch: 70, Loss: 0.012528\n",
      "Train - Epoch 7, Batch: 80, Loss: 0.002696\n",
      "Train - Epoch 7, Batch: 90, Loss: 0.005081\n",
      "Train - Epoch 7, Batch: 100, Loss: 0.041449\n",
      "Train - Epoch 7, Batch: 110, Loss: 0.016965\n",
      "Train - Epoch 7, Batch: 120, Loss: 0.048532\n",
      "Train - Epoch 7, Batch: 130, Loss: 0.008761\n",
      "Train - Epoch 7, Batch: 140, Loss: 0.064691\n",
      "Train - Epoch 7, Batch: 150, Loss: 0.017950\n",
      "Train - Epoch 7, Batch: 160, Loss: 0.013072\n",
      "Train - Epoch 7, Batch: 170, Loss: 0.038870\n",
      "Train - Epoch 7, Batch: 180, Loss: 0.039401\n",
      "Train - Epoch 7, Batch: 190, Loss: 0.005112\n",
      "Train - Epoch 7, Batch: 200, Loss: 0.034036\n",
      "Train - Epoch 7, Batch: 210, Loss: 0.020852\n",
      "Train - Epoch 7, Batch: 220, Loss: 0.006070\n",
      "Train - Epoch 7, Batch: 230, Loss: 0.013487\n",
      "Train - Epoch 7, Batch: 240, Loss: 0.003171\n",
      "Train - Epoch 7, Batch: 250, Loss: 0.056005\n",
      "Train - Epoch 7, Batch: 260, Loss: 0.033666\n",
      "Train - Epoch 7, Batch: 270, Loss: 0.054839\n",
      "Train - Epoch 7, Batch: 280, Loss: 0.035081\n",
      "Train - Epoch 7, Batch: 290, Loss: 0.005589\n",
      "Train - Epoch 7, Batch: 300, Loss: 0.045387\n",
      "Train - Epoch 7, Batch: 310, Loss: 0.007897\n",
      "Train - Epoch 7, Batch: 320, Loss: 0.005739\n",
      "Train - Epoch 7, Batch: 330, Loss: 0.068192\n",
      "Train - Epoch 7, Batch: 340, Loss: 0.016495\n",
      "Train - Epoch 7, Batch: 350, Loss: 0.026726\n",
      "Train - Epoch 7, Batch: 360, Loss: 0.048786\n",
      "Train - Epoch 7, Batch: 370, Loss: 0.080612\n",
      "Train - Epoch 7, Batch: 380, Loss: 0.044537\n",
      "Train - Epoch 7, Batch: 390, Loss: 0.011458\n",
      "Train - Epoch 7, Batch: 400, Loss: 0.034725\n",
      "Train - Epoch 7, Batch: 410, Loss: 0.006817\n",
      "Train - Epoch 7, Batch: 420, Loss: 0.005561\n",
      "Test Avg. Loss: 0.000313, Accuracy: 0.987400\n",
      "EPOCH 7 ...\n",
      "Validation Accuracy = 0.987\n",
      "\n",
      "Model saved\n",
      "Train - Epoch 8, Batch: 0, Loss: 0.002189\n",
      "Train - Epoch 8, Batch: 10, Loss: 0.002141\n",
      "Train - Epoch 8, Batch: 20, Loss: 0.003944\n",
      "Train - Epoch 8, Batch: 30, Loss: 0.010529\n",
      "Train - Epoch 8, Batch: 40, Loss: 0.004917\n",
      "Train - Epoch 8, Batch: 50, Loss: 0.004597\n",
      "Train - Epoch 8, Batch: 60, Loss: 0.005842\n",
      "Train - Epoch 8, Batch: 70, Loss: 0.007076\n",
      "Train - Epoch 8, Batch: 80, Loss: 0.007929\n",
      "Train - Epoch 8, Batch: 90, Loss: 0.004956\n",
      "Train - Epoch 8, Batch: 100, Loss: 0.103595\n",
      "Train - Epoch 8, Batch: 110, Loss: 0.022453\n",
      "Train - Epoch 8, Batch: 120, Loss: 0.025371\n",
      "Train - Epoch 8, Batch: 130, Loss: 0.003536\n",
      "Train - Epoch 8, Batch: 140, Loss: 0.031202\n",
      "Train - Epoch 8, Batch: 150, Loss: 0.024524\n",
      "Train - Epoch 8, Batch: 160, Loss: 0.039833\n",
      "Train - Epoch 8, Batch: 170, Loss: 0.046948\n",
      "Train - Epoch 8, Batch: 180, Loss: 0.046450\n",
      "Train - Epoch 8, Batch: 190, Loss: 0.001500\n",
      "Train - Epoch 8, Batch: 200, Loss: 0.013042\n",
      "Train - Epoch 8, Batch: 210, Loss: 0.016178\n",
      "Train - Epoch 8, Batch: 220, Loss: 0.011944\n",
      "Train - Epoch 8, Batch: 230, Loss: 0.024174\n",
      "Train - Epoch 8, Batch: 240, Loss: 0.006639\n",
      "Train - Epoch 8, Batch: 250, Loss: 0.007664\n",
      "Train - Epoch 8, Batch: 260, Loss: 0.009558\n",
      "Train - Epoch 8, Batch: 270, Loss: 0.014411\n",
      "Train - Epoch 8, Batch: 280, Loss: 0.042259\n",
      "Train - Epoch 8, Batch: 290, Loss: 0.017071\n",
      "Train - Epoch 8, Batch: 300, Loss: 0.012085\n",
      "Train - Epoch 8, Batch: 310, Loss: 0.040309\n",
      "Train - Epoch 8, Batch: 320, Loss: 0.024868\n",
      "Train - Epoch 8, Batch: 330, Loss: 0.009859\n",
      "Train - Epoch 8, Batch: 340, Loss: 0.014633\n",
      "Train - Epoch 8, Batch: 350, Loss: 0.013030\n",
      "Train - Epoch 8, Batch: 360, Loss: 0.002489\n",
      "Train - Epoch 8, Batch: 370, Loss: 0.001924\n",
      "Train - Epoch 8, Batch: 380, Loss: 0.043286\n",
      "Train - Epoch 8, Batch: 390, Loss: 0.004871\n",
      "Train - Epoch 8, Batch: 400, Loss: 0.033475\n",
      "Train - Epoch 8, Batch: 410, Loss: 0.005785\n",
      "Train - Epoch 8, Batch: 420, Loss: 0.024127\n",
      "Test Avg. Loss: 0.000371, Accuracy: 0.986000\n",
      "EPOCH 8 ...\n",
      "Validation Accuracy = 0.986\n",
      "\n",
      "Model saved\n",
      "Train - Epoch 9, Batch: 0, Loss: 0.022500\n",
      "Train - Epoch 9, Batch: 10, Loss: 0.024572\n",
      "Train - Epoch 9, Batch: 20, Loss: 0.016041\n",
      "Train - Epoch 9, Batch: 30, Loss: 0.024490\n",
      "Train - Epoch 9, Batch: 40, Loss: 0.069733\n",
      "Train - Epoch 9, Batch: 50, Loss: 0.020000\n",
      "Train - Epoch 9, Batch: 60, Loss: 0.011982\n",
      "Train - Epoch 9, Batch: 70, Loss: 0.010947\n",
      "Train - Epoch 9, Batch: 80, Loss: 0.006466\n",
      "Train - Epoch 9, Batch: 90, Loss: 0.004119\n",
      "Train - Epoch 9, Batch: 100, Loss: 0.011382\n",
      "Train - Epoch 9, Batch: 110, Loss: 0.005836\n",
      "Train - Epoch 9, Batch: 120, Loss: 0.007831\n",
      "Train - Epoch 9, Batch: 130, Loss: 0.007731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Epoch 9, Batch: 140, Loss: 0.001788\n",
      "Train - Epoch 9, Batch: 150, Loss: 0.004155\n",
      "Train - Epoch 9, Batch: 160, Loss: 0.007682\n",
      "Train - Epoch 9, Batch: 170, Loss: 0.005256\n",
      "Train - Epoch 9, Batch: 180, Loss: 0.008544\n",
      "Train - Epoch 9, Batch: 190, Loss: 0.006473\n",
      "Train - Epoch 9, Batch: 200, Loss: 0.019357\n",
      "Train - Epoch 9, Batch: 210, Loss: 0.035918\n",
      "Train - Epoch 9, Batch: 220, Loss: 0.016677\n",
      "Train - Epoch 9, Batch: 230, Loss: 0.057461\n",
      "Train - Epoch 9, Batch: 240, Loss: 0.002089\n",
      "Train - Epoch 9, Batch: 250, Loss: 0.015452\n",
      "Train - Epoch 9, Batch: 260, Loss: 0.000634\n",
      "Train - Epoch 9, Batch: 270, Loss: 0.068476\n",
      "Train - Epoch 9, Batch: 280, Loss: 0.025930\n",
      "Train - Epoch 9, Batch: 290, Loss: 0.013122\n",
      "Train - Epoch 9, Batch: 300, Loss: 0.016229\n",
      "Train - Epoch 9, Batch: 310, Loss: 0.018616\n",
      "Train - Epoch 9, Batch: 320, Loss: 0.001479\n",
      "Train - Epoch 9, Batch: 330, Loss: 0.013950\n",
      "Train - Epoch 9, Batch: 340, Loss: 0.012650\n",
      "Train - Epoch 9, Batch: 350, Loss: 0.010134\n",
      "Train - Epoch 9, Batch: 360, Loss: 0.016028\n",
      "Train - Epoch 9, Batch: 370, Loss: 0.007393\n",
      "Train - Epoch 9, Batch: 380, Loss: 0.009457\n",
      "Train - Epoch 9, Batch: 390, Loss: 0.016474\n",
      "Train - Epoch 9, Batch: 400, Loss: 0.033096\n",
      "Train - Epoch 9, Batch: 410, Loss: 0.037207\n",
      "Train - Epoch 9, Batch: 420, Loss: 0.038497\n",
      "Test Avg. Loss: 0.000317, Accuracy: 0.989000\n",
      "EPOCH 9 ...\n",
      "Validation Accuracy = 0.989\n",
      "\n",
      "Model saved\n",
      "Train - Epoch 10, Batch: 0, Loss: 0.008329\n",
      "Train - Epoch 10, Batch: 10, Loss: 0.000654\n",
      "Train - Epoch 10, Batch: 20, Loss: 0.003108\n",
      "Train - Epoch 10, Batch: 30, Loss: 0.012728\n",
      "Train - Epoch 10, Batch: 40, Loss: 0.006848\n",
      "Train - Epoch 10, Batch: 50, Loss: 0.050149\n",
      "Train - Epoch 10, Batch: 60, Loss: 0.041179\n",
      "Train - Epoch 10, Batch: 70, Loss: 0.002326\n",
      "Train - Epoch 10, Batch: 80, Loss: 0.017238\n",
      "Train - Epoch 10, Batch: 90, Loss: 0.033426\n",
      "Train - Epoch 10, Batch: 100, Loss: 0.017501\n",
      "Train - Epoch 10, Batch: 110, Loss: 0.012444\n",
      "Train - Epoch 10, Batch: 120, Loss: 0.078182\n",
      "Train - Epoch 10, Batch: 130, Loss: 0.009229\n",
      "Train - Epoch 10, Batch: 140, Loss: 0.015421\n",
      "Train - Epoch 10, Batch: 150, Loss: 0.013413\n",
      "Train - Epoch 10, Batch: 160, Loss: 0.026962\n",
      "Train - Epoch 10, Batch: 170, Loss: 0.016100\n",
      "Train - Epoch 10, Batch: 180, Loss: 0.039060\n",
      "Train - Epoch 10, Batch: 190, Loss: 0.012994\n",
      "Train - Epoch 10, Batch: 200, Loss: 0.034616\n",
      "Train - Epoch 10, Batch: 210, Loss: 0.003649\n",
      "Train - Epoch 10, Batch: 220, Loss: 0.007363\n",
      "Train - Epoch 10, Batch: 230, Loss: 0.032446\n",
      "Train - Epoch 10, Batch: 240, Loss: 0.003790\n",
      "Train - Epoch 10, Batch: 250, Loss: 0.012285\n",
      "Train - Epoch 10, Batch: 260, Loss: 0.034345\n",
      "Train - Epoch 10, Batch: 270, Loss: 0.014744\n",
      "Train - Epoch 10, Batch: 280, Loss: 0.002450\n",
      "Train - Epoch 10, Batch: 290, Loss: 0.009963\n",
      "Train - Epoch 10, Batch: 300, Loss: 0.008046\n",
      "Train - Epoch 10, Batch: 310, Loss: 0.006180\n",
      "Train - Epoch 10, Batch: 320, Loss: 0.049898\n",
      "Train - Epoch 10, Batch: 330, Loss: 0.021899\n",
      "Train - Epoch 10, Batch: 340, Loss: 0.001188\n",
      "Train - Epoch 10, Batch: 350, Loss: 0.023806\n",
      "Train - Epoch 10, Batch: 360, Loss: 0.003852\n",
      "Train - Epoch 10, Batch: 370, Loss: 0.002501\n",
      "Train - Epoch 10, Batch: 380, Loss: 0.004453\n",
      "Train - Epoch 10, Batch: 390, Loss: 0.056778\n",
      "Train - Epoch 10, Batch: 400, Loss: 0.011351\n",
      "Train - Epoch 10, Batch: 410, Loss: 0.002248\n",
      "Train - Epoch 10, Batch: 420, Loss: 0.020510\n",
      "Test Avg. Loss: 0.000285, Accuracy: 0.989800\n",
      "EPOCH 10 ...\n",
      "Validation Accuracy = 0.990\n",
      "\n",
      "Model saved\n",
      "Train - Epoch 11, Batch: 0, Loss: 0.001990\n",
      "Train - Epoch 11, Batch: 10, Loss: 0.025720\n",
      "Train - Epoch 11, Batch: 20, Loss: 0.006306\n",
      "Train - Epoch 11, Batch: 30, Loss: 0.002780\n",
      "Train - Epoch 11, Batch: 40, Loss: 0.014801\n",
      "Train - Epoch 11, Batch: 50, Loss: 0.001175\n",
      "Train - Epoch 11, Batch: 60, Loss: 0.005529\n",
      "Train - Epoch 11, Batch: 70, Loss: 0.004251\n",
      "Train - Epoch 11, Batch: 80, Loss: 0.001953\n",
      "Train - Epoch 11, Batch: 90, Loss: 0.001319\n",
      "Train - Epoch 11, Batch: 100, Loss: 0.035699\n",
      "Train - Epoch 11, Batch: 110, Loss: 0.170617\n",
      "Train - Epoch 11, Batch: 120, Loss: 0.004610\n",
      "Train - Epoch 11, Batch: 130, Loss: 0.005508\n",
      "Train - Epoch 11, Batch: 140, Loss: 0.038826\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m best_val_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m200\u001b[39m):\n\u001b[0;32m----> 6\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     validation_accuracy, validation_predictions \u001b[38;5;241m=\u001b[39m evaluate(valid_loader, dataset_valid)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEPOCH \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m ...\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(e))\n",
      "Cell \u001b[0;32mIn [6], line 6\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m      4\u001b[0m net\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      5\u001b[0m loss_list, batch_list \u001b[38;5;241m=\u001b[39m [], []\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (images, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m      7\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m      8\u001b[0m     output \u001b[38;5;241m=\u001b[39m net(images\u001b[38;5;241m.\u001b[39mcuda())\n",
      "File \u001b[0;32m~/miniconda3/envs/GAN/lib/python3.10/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/GAN/lib/python3.10/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/GAN/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/GAN/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/GAN/lib/python3.10/site-packages/torch/utils/data/dataset.py:295\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idx]]\n\u001b[0;32m--> 295\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/GAN/lib/python3.10/site-packages/torchvision/datasets/mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    142\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 145\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[0;32m~/miniconda3/envs/GAN/lib/python3.10/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/miniconda3/envs/GAN/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/GAN/lib/python3.10/site-packages/torchvision/transforms/transforms.py:270\u001b[0m, in \u001b[0;36mNormalize.forward\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;124;03m        tensor (Tensor): Tensor image to be normalized.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;124;03m        Tensor: Normalized Tensor image.\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 270\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/GAN/lib/python3.10/site-packages/torchvision/transforms/functional.py:360\u001b[0m, in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg should be Tensor Image. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensor)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 360\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/GAN/lib/python3.10/site-packages/torchvision/transforms/functional_tensor.py:920\u001b[0m, in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnormalize\u001b[39m(tensor: Tensor, mean: List[\u001b[38;5;28mfloat\u001b[39m], std: List[\u001b[38;5;28mfloat\u001b[39m], inplace: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    918\u001b[0m     _assert_image_tensor(tensor)\n\u001b[0;32m--> 920\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    921\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput tensor should be a float tensor. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    923\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m3\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Training...\")\n",
    "print()\n",
    "best_val_acc = 0\n",
    "\n",
    "for e in range(1, 200):\n",
    "    train(e)\n",
    "    validation_accuracy, validation_predictions = evaluate(valid_loader, dataset_valid)\n",
    "    print(\"EPOCH {} ...\".format(e))\n",
    "    print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "    print()\n",
    "    \n",
    "    if validation_accuracy > best_val_acc:\n",
    "        validation_accuracy = best_val_acc\n",
    "\n",
    "        torch.save(\n",
    "            {\n",
    "                'lenet': net.state_dict(),\n",
    "            },\n",
    "            ('./save/kiet_mnist_classifier.pt'),\n",
    "        )\n",
    "        print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63f982c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Avg. Loss: 0.000265, Accuracy: 0.989900\n",
      "Test Accuracy = 0.990\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load('./save/kiet_mnist_classifier.pt')\n",
    "net.load_state_dict(checkpoint['lenet'])\n",
    "\n",
    "test_accuracy, test_predictions = evaluate(test_loader, dataset_test)\n",
    "print(\"Test Accuracy = {:.3f}\".format(test_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
